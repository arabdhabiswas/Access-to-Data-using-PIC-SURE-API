{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIC-SURE API tutorial using the Undiagnosed Diseases Network (UDN) database\n",
    "This is a tutorial notebook, aimed to be quickly up and running with the R PIC-SURE API. It covers the main functionalities of the API.\n",
    "\n",
    "## R PIC-SURE API\n",
    "### What is PIC-SURE?\n",
    "Databases exposed through the PIC-SURE API encompass a wide heterogeneity of architectures and data organizations underneath. PIC-SURE hides this complexity and exposes the different databases in the same format, allowing researchers to focus on the analysis and medical insights, thus easing the process of reproducible sciences.\n",
    "\n",
    "### More about PIC-SURE\n",
    "PIC-SURE stands for Patient-centered Information Commons: Standardized Unification of Research Elements. The API is available in two different programming languages, Python and R, allowing investigators to query databases in the same way using either of those languages.\n",
    "\n",
    "PIC-SURE is a larger project from which the R/python PIC-SURE API is only a brick. Among other things, PIC-SURE also offers a graphical user interface that allows researchers to explore variables across multiple studies, filter patients that match criteria, and create cohorts from this interactive exploration.\n",
    "\n",
    "The API is actively developed by the Avillach-Lab at Harvard Medical School.\n",
    "\n",
    "GitHub repo:\n",
    "\n",
    "* https://github.com/hms-dbmi/pic-sure-r-adapter-hpds\n",
    "* https://github.com/hms-dbmi/pic-sure-r-client\n",
    "* https://github.com/hms-dbmi/pic-sure-biodatacatalyst-r-adapter-hpds\n",
    "\n",
    "---\n",
    "\n",
    "## Getting your own user-specific security token\n",
    "**Before running this notebook, please be sure to review the \"Get your security token\" documentation, which exists in the NHLBI_BioData_Catalyst [README.md file](https://github.com/hms-dbmi/Access-to-Data-using-PIC-SURE-API/tree/master/NHLBI_BioData_Catalyst#get-your-security-token). It explains about how to get a security token, which is mandatory to access the databases.**\n",
    "\n",
    "### Environment set-up\n",
    "\n",
    "#### Pre-requisites: \n",
    "* R version >= 3.6\n",
    "\n",
    "#### Package installation and imports\n",
    "The installation of some packages may take some time, please be patient.\n",
    "- packages listed in the `requirements.R` file\n",
    "- PIC-SURE API components (from Github)\n",
    "    - PIC-SURE Adapter\n",
    "    - PIC-SURE Client\n",
    "\n",
    "#### Install latest R PIC-SURE API libraries from GitHub\n",
    "To install the PIC-SURE libraries from GitHub, we need to install first the `devtools` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system(command = 'conda install -c conda-forge r-devtools --yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Sys.setenv(TAR = \"/bin/tar\")\n",
    "options(unzip = \"internal\")\n",
    "install.packages(\"https://cran.r-project.org/src/contrib/Archive/devtools/devtools_1.13.6.tar.gz\", repos=NULL, type=\"source\")\n",
    "install.packages(\"https://cran.r-project.org/src/contrib/R6_2.5.1.tar.gz\", repos=NULL, type=\"source\")\n",
    "install.packages(\"https://cran.r-project.org/src/contrib/hash_2.2.6.1.tar.gz\", repos=NULL, type=\"source\")\n",
    "install.packages(c(\"urltools\"),repos = \"http://cran.us.r-project.org\")\n",
    "devtools::install_github(\"hms-dbmi/pic-sure-r-client\", force=T)\n",
    "devtools::install_github(\"hms-dbmi/pic-sure-r-adapter-hpds\", force=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load user-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_lib for pic-sure\n",
    "source(\"R_lib/utils.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to a PIC-SURE resource\n",
    "\n",
    "### 1. Connect to the UDN data network\n",
    "The following is required to get access to data through the PIC-SURE API: \n",
    "- Network URL\n",
    "- Resource id\n",
    "- User-specific security token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection to the PIC-SURE API w/ key\n",
    "# network information\n",
    "PICSURE_network_URL <- \"https://udn.hms.harvard.edu/picsure\"\n",
    "resource_id <- \"c23b6814-7e5b-48d2-80d9-65511d7d2051\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token is the individual user key given to connect to the UDN resource\n",
    "token_file <- \"token.txt\"\n",
    "my_token <- scan(token_file, what = \"character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get connection object\n",
    "connection <- picsure::connect(url = PICSURE_network_URL,\n",
    "                                 token = my_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get resource object\n",
    "resource <- hpds::get.resource(connection,\n",
    "                               resourceUUID = resource_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two objects are created here: a `connection` and a `resource` object.\n",
    "\n",
    "Since we will only be using a single resource, **the `resource` object is actually the only one we will need to proceed with data analysis hereafter**.\n",
    "\n",
    "It is connected to the specific data source ID we specified and enables us to query and retrieve data from this database.\n",
    "\n",
    "#### Getting help with the R PIC-SURE API\n",
    "\n",
    "You can get help with PIC-SURE library functions by using the `?` operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get function documentation\n",
    "?hpds::get.resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explore the data: data structures description\n",
    "\n",
    "There are two methods to explore the data from which the user get two different data structures: a **dictionary object** to explore variables and a **query object** to explore the patient records in UDN. \n",
    "\n",
    "**Methods**:\n",
    "\n",
    "    * Search variables: find.in.dictionary() method\n",
    "    * Retrieve data: query() methods\n",
    "\n",
    "**Data structures**:\n",
    "\n",
    "    * Dictionary object structure\n",
    "    * Query object structure\n",
    "    \n",
    "\n",
    "#### Explore variables using the _dictionary_\n",
    "\n",
    "Once a connection to the desired resource has been established, we first need to get a quick idea of which variables are available in the database. To this end, we will use the `dictionary` method of the `resource` object.\n",
    "\n",
    "A dictionary object offers the possibility to retrieve information about either matching variables according to a specific term or all available variables, using the `find.in.dictionary()` method. For instance, looking for variables containing the term 'aplasia' is done this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary object and search for a specific term, in this example for \"aplasia\"\n",
    "lookup <- hpds::find.in.dictionary(resource, \"aplasia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created the dictionary object with only variables matched by the search term. To retrieve the search result from dictionary objects we have 4 different methods: `extract.count()`, `extract.keys()`, and `extract.entries()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# description of the dictionary search content\n",
    "print(list(\"Count\"   = hpds::extract.count(lookup), \n",
    "           \"Keys\"    = hpds::extract.keys(lookup)[0:2],\n",
    "           \"Entries\" = hpds::extract.entries(lookup)[1:5,0:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hpds::extract.entries()** enables us to get the result of the dictionary search in a data.frame format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show table of records from the dictionary object\n",
    "hpds::extract.entries(lookup) %>% tail(, n =2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve information about **ALL** variables. We do it without specifying a term in the dictionary search method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we search for ALL variables, and extract the resulting entries\n",
    "plain_variablesDict <- hpds::find.in.dictionary(resource, \"\") %>% hpds::extract.entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description of the whole dictionary of variables\n",
    "print(dim(plain_variablesDict))\n",
    "head(plain_variablesDict, n = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UDN network resource contains 13414 variables described by 11 data fields:\n",
    "* name\n",
    "* HpdsDataType\n",
    "* description\n",
    "* categorical\n",
    "* categoryValues\n",
    "* values\n",
    "* continuous\n",
    "* min\n",
    "* max\n",
    "* observationCount\n",
    "* patientCount\n",
    "\n",
    "The dictionary provides various information about the variables, such as:\n",
    "\n",
    "* observationCount: number of entries with non-null value\n",
    "* categorical: type of the variables, True if categorical, False if continuous/numerical\n",
    "* min/max: only provided for non-categorical variables\n",
    "* HpdsDataType: 'phenotypes' or 'genotypes'. Currently, the API only expsoses'phenotypes' variables\n",
    "\n",
    "Hence, it enables us to:\n",
    "\n",
    "* Use the various variables information as criteria for variable selection.\n",
    "* Use the row names of the DataFrame to get the actual variables names, to be used in the query, as shown below.\n",
    " \n",
    "Variable names (`name` **column** in the dataframe), as currently implemented in the API, aren't straightforward to use because:\n",
    "\n",
    "1. Very long\n",
    "2. Presence of backslashes that requires modification right after copy-pasting.\n",
    "\n",
    "However, using the dictionary to select variables can help to deal with this. \n",
    "\n",
    "##### Parsing variable names\n",
    "We can use an utils function, `get_multiIndex()`, defined in R_lib/utils.R, to add a little more information and ease working with variables names.\n",
    "\n",
    "Although not an official feature of the API, such functionality illustrates how to quickly scan and select groups of related variables.\n",
    "\n",
    "Printing part of the \"parsed names\" Dictionary allows to quickly see the tree-like organisation of the variables. Moreover, original and simplified variable names are now stored respectively in the \"name\" and \"simplified_name\" columns (simplified variable names is simply the last component of the variable name, which usually makes the most sense to know what each variable is about)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the variables tree hierarchy from the variables name\n",
    "variablesDict <- get_multiIndex_variablesDict(plain_variablesDict)\n",
    "head(variablesDict, n = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simple example to illustrate the ease of use of a multiIndex dictionary. Let's say we are interested in filtering variables related to \"aplasias\" in the \"nervous system\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_system <- variablesDict[,3] == \"Abnormality of the nervous system\"\n",
    "mask_abnormality <- grepl(\"Aplasia\", variablesDict[[\"name\"]])\n",
    "filtered_variables <- variablesDict[mask_system & mask_abnormality,]\n",
    "print(dim(filtered_variables))\n",
    "head(filtered_variables, n = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although pretty simple, it can be easily combined with other filters to quickly select necessary variables.\n",
    "\n",
    "#### Explore patient records using _query_\n",
    "\n",
    "Beside from the dictionary, the second cornerstone of the API are the query methods (`hpds::query.select`, `hpds::query.require`, `hpds::query.anyof`, `hpds::query.filter`). They are the entering point to **query and retrieve data from the resource**.\n",
    "\n",
    "First, we need to create a query object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a query object for the resource\n",
    "my_query <- hpds::new.query(resource = resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query object created will be then passed to the different query methods to build the query:  <font color='orange'>hpds::query.select.add(), hpds::query.require.add(), hpds::query.anyof.add(), and hpds::query.filter.add()</font>. Each of those methods accept a query object, a list of variable names, and eventual additional parameters.\n",
    "\n",
    "| Method | Arguments / Input | Output|\n",
    "|--------|-------------------|-------|\n",
    "| query.select.add() | variable names (string) or list of strings | all variables included in the list (no record subsetting)|\n",
    "| query.require.add() | variable names (string) or list of strings | all variables; only records that do not contain null values for input variables |\n",
    "| query.anyof.add() | variable names (string) or list of strings | all variables; only records that contain at least one non-null value for input variables |\n",
    "| query.filter.add() | variable name and additional filtering values | input variable; only records that match filter criteria |\n",
    "\n",
    "All those 4 methods can be combined when building a query. The record eventually returned by the query have to meet all the different specified filters.\n",
    "\n",
    "##### Building the query\n",
    "Let's say we want to check some demographics about the data in UDN. We will filter to variables that have observation counts > 50% patient counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select demographic variable names\n",
    "demographicsDict <- hpds::find.in.dictionary(resource, \"demographics\") %>% \n",
    "    hpds::extract.entries()\n",
    "mask_obs <- demographicsDict %>% filter(observationCount > patientCount * 0.50)\n",
    "selected_varnames <- mask_obs %>% pull(name) \n",
    "print(paste0('We have found ', length(selected_varnames), ' demographics variable(s) which have observation counts > 50% of patient counts (listed below).'))\n",
    "selected_varnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may warning messages containing the following text when building your query with multiple variables: \n",
    "“the condition has length > 1 and only the first element will be used” - this can be ignored.\n",
    "\n",
    "To double check that your filter has been applied to your query, you can run ```hpds::query.show(query = my_query)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and query for demographics patient data\n",
    "hpds::query.select.add(query=my_query, keys=selected_varnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retrieving the data\n",
    "Once our query object is  built, we use the `query.run()` method to retrieve the data corresponding to our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# retrieve the query result as a dataframe\n",
    "demographics_data <- hpds::query.run(my_query, result.type=\"dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dim(demographics_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(demographics_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Working with Variant Data\n",
    "You can also use the query object to explore variant data. In this example, let's look at variants for the CHD8 gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new query\n",
    "my_query <- hpds::new.query(resource = resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a filter for a categorical variant: CHD8\n",
    "hpds::query.filter.add(query=my_query, keys=\"Gene_with_variant\", \"CHD8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before calling the full data frame of variants, let's ensure that the approximate total count of variants being returned by our query is of a reasonable size. Queries returning more than 100,000 variants could crash your workbook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variantCount <- hpds::query.run(my_query, result.type=\"variantsApproximateCount\")\n",
    "variantCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example of a genomic filter is looking at the variant frequency.\n",
    "- Novel variants are not found in the rest of the population\n",
    "- Rare variants are found in <1% of the population\n",
    "- Common variants are found in >= 1% of the population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering by Gene prior to adding additional genomic or phenotypic filters is good practice to ensure the system does not become overwhelmed by a very large query.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example querying for rare variants in the following genes of interest: CHD8, CHD9, and CHCHD10\n",
    "my_query <- hpds::new.query(resource = resource)\n",
    "hpds::query.filter.add(query=my_query, keys=\"Gene_with_variant\", list(\"CHD8\", \"CHD9\", \"CHCHD10\")) \n",
    "hpds::query.filter.add(query=my_query, keys=\"Variant_frequency_as_text\", \"Rare\") \n",
    "variant_data <- hpds::query.run(my_query, result.type=\"variantsDataFrame\")\n",
    "\n",
    "head(variant_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(variant_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further add a phenotypic filter to this existing genomic query, to find rare variants in the genes of interest, where the sex of the participant is \"Female\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example combining variant and phenotype queries\n",
    "hpds::query.filter.add(query=my_query, keys=\"\\\\00_Demographics\\\\Sex\\\\\", \"Female\")\n",
    "variant_data <- hpds::query.run(my_query, result.type=\"variantsDataFrame\")\n",
    "head(variant_data)\n",
    "dim(variant_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(demographics_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Patient ID Mapping\n",
    "You may notice that the Patient IDs found in the demographics dataframe do not match the Patient IDs found from our genomic query. Phenotypic queries return 'Patient IDs' while genomic queries return 'UDN IDs'. You can create a mapping between these two types of IDs as demonstrated below, which you can use to merge phenotypic and genomic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_query <- hpds::new.query(resource = resource)\n",
    "hpds::query.select.add(query=mapping_query, keys='\\\\000_UDN ID\\\\')\n",
    "id_mapping <- hpds::query.run(mapping_query, result.type=\"dataframe\")\n",
    "head(id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
