{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIC-SURE API tutorial using CureSC database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial notebook, aimed for the user to be quickly up and running with the python PIC-SURE API. It covers the main functionalities of the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIC-SURE python API \n",
    "### What is PIC-SURE? \n",
    "\n",
    "PIC-SURE stands for Patient-centered Information Commons: Standardized Unification of Research Elements. Original data exposed through PIC-SURE API encompasses a large heterogeneity of data organization underneath. PIC-SURE hides this complexity and exposes the different study datasets in a single tabular format. By simplifying the process of data extraction, it allows investigators to focus on the downstream analyses and to facilitate reproducible sciences.\n",
    "\n",
    "### More about PIC-SURE\n",
    "The API is available in two different programming languages, python and R, allowing investigators to query datasets in the same way using either of language. The R/python PIC-SURE API is a small part of the entire PIC-SURE platform.\n",
    "\n",
    "The API is actively developed by the Avillach Lab at Harvard Medical School.\n",
    "\n",
    "GitHub repo:\n",
    "* https://github.com/hms-dbmi/pic-sure-python-adapter-hpds\n",
    "* https://github.com/hms-dbmi/pic-sure-python-client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -------   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting your own user-specific security token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running this notebook, please be sure you have [added your security token](https://github.com/hms-dbmi/Access-to-Data-using-PIC-SURE-API/tree/master/Cure_Sickle_Cell#get-your-security-token). This documentation contains an explanation about how to get a security token, which is required to access the databases.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisite\n",
    "- python 3.6 or later (although earlier versions of python 3 must work too)\n",
    "- pip: python package manager, already available in most system with a python interpreter installed ([pip installation instructions](https://pip.pypa.io/en/stable/installing/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPython magic command\n",
    "\n",
    "The following code loads the `autoreload` IPython extension. Although `autoreload` is not necessary to execute the rest of the notebook, it does enable the notebook to reload every dependency each time python code is executed.  This will enable the notebook to take into account changes in external files imported, such as the user defined functions stored in separate file, without needing to manually reload libraries. This is helpful when developing interactively. Learn more about [IPython Magic commands](https://ipython.readthedocs.io/en/stable/interactive/magics.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of required python packages\n",
    "\n",
    "Using the pip package manager, we install the packages listed in the `requirements.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat requirements.txt # List contents of the requirements.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the external dependencies, as well as user-defined functions stored in the `python_lib` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import PicSureHpdsLib\n",
    "import PicSureClient\n",
    "\n",
    "from python_lib.utils import get_multiIndex_variablesDict, get_dic_renaming_vars, joining_variablesDict_onCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NB: This Jupyter Notebook has been written using PIC-SURE API following versions:\\n- PicSureClient: 0.1.0\\n- PicSureHpdsLib: 1.1.0\\n\")\n",
    "print(\"The PIC-SURE API libraries versions you've been downloading are: \\n- PicSureClient: {0}\\n- PicSureHpdsLib: {1}\".format(PicSureClient.__version__, PicSureHpdsLib.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up the options for displaying tables and plots in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrame display options\n",
    "pd.set_option(\"max.rows\", 100)\n",
    "\n",
    "# Matplotlib parameters options\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    " \n",
    "# Prints: [8.0, 6.0]\n",
    "fig_size[0] = 14\n",
    "fig_size[1] = 8\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 14}\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to a PIC-SURE network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need the following information before connecting to the PIC-SURE network:\n",
    "* resource_id: ID of the resource that you are trying to access. You can leave the default value for this project.\n",
    "* token_file: A text file called token.txt should contain the token retrieved from you user profile in PIC-SURE UI. This file needs to be located at the R root folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_id = \"57e29a43-38c3-4c4b-84c9-dda8138badbe\"\n",
    "token_file = \"token.txt\"\n",
    "PICSURE_network_URL = \"https://curesc.hms.harvard.edu/picsure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(token_file, \"r\") as f:\n",
    "    my_token = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = PicSureClient.Client()\n",
    "connection = client.connect(PICSURE_network_URL, my_token, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = PicSureHpdsLib.Adapter(connection)\n",
    "resource = adapter.useResource(resource_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two objects are created here: a `connection` and a `resource` object, using the `picsure` and `hpds` libraries, respectively. \n",
    "\n",
    "Since will only be using one single resource, **the `resource` object is the only one we will need to proceed with data analysis hereafter.** It should be noted that the `connection` object is useful to get access to different databases stored in different resources. \n",
    "\n",
    "The `resource` object is connected to the specific data source ID we specified and enables us to query and retrieve data from this source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting help with the PIC-SURE python API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `help()` method prints out helper message for any PIC-SURE library function. For example, we can learn more about getting a resource using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output tells us that this `resource` object has 2 methods, and it gives insights about their function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the *variables dictionary*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a connection to the desired resource has been established, we first need to get a quick idea of which variables are available in the database. We will use the `dictionary` method of the `resource` object to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `dictionary` instance offers the possibility to retrieve matching records according to a specific term. The `find()` method can be used to retrieve information about all available variables. For instance, looking for variables containing the term 'Sex' is done this way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = resource.dictionary()\n",
    "dictionary_search = dictionary.find(\"Sex\")\n",
    "dictionary_search.DataFrame().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects created by the `dictionary.find` exposes the search result using 4 different methods: `.count()`, `.keys()`, `.entries()`, and `.DataFrame()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint({\"Count\": dictionary_search.count(), \n",
    "        \"Keys\": dictionary_search.keys()[0:3],\n",
    "        \"Entries\": dictionary_search.entries()[0:3]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`.DataFrame()` enables to get the result of the dictionary search in a pandas DataFrame format** \n",
    "\n",
    "The dictionary provides various information about the variables, such as:\n",
    "- observationCount: number of entries with non-null value\n",
    "- categorical: type of the variables, True if categorical, False if continuous/numerical\n",
    "- min/max: only provided for non-categorical variables\n",
    "- HpdsDataType: 'phenotypes' or 'genotypes'. Currently, the API only expsoses 'phenotypes' variables\n",
    "\n",
    "Hence, it enables to:\n",
    "* Use the various variables information as criteria for variable selection.\n",
    "* Use the row names of the DataFrame to get the actual variables names, to be used in the query, as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable names as currently implemented in the API aren't straightforward to use for a few reasons:\n",
    "1. Very long\n",
    "2. Presence of backslashes that requires modification right after copy-pasting. \n",
    "\n",
    "However, using the dictionary to select variables can help to deal with this. Let's say we want to retrieve every variable from the different substudies available in the resource, such as Cure Sickle Cell related studies. One way to proceed would be to retrieve the whole dictionary for those variables in the form of a DataFrame, as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_variablesDict = resource.dictionary().find().DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `dictionary.find()` function without arguments return every entries, as shown in the help documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource.dictionary().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_variablesDict.iloc[10:20,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Full Data Dictionary to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to export the data dictionary first we will create a Pandas dataframe called `fullVariableDict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullVariableDict = resource.dictionary().find().DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that `fullVariableDict` dataframe contains some values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullVariableDict.iloc[0:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullVariableDict.to_csv('data_dictionary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see a data_dictionary.csv in the Jupyter Hub file explorer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable dictionary + pandas multiIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though helpful, we can use a simple user-defined function (`get_multiIndex_variablesDict`) to add a little more information and ease working with long variables names. It takes advantage of pandas MultiIndex functionality [see pandas official documentation on this topic](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html).\n",
    "\n",
    "Although not an official feature of the API, such functionality illustrates how to quickly scan and select groups of related variables.\n",
    "\n",
    "Printing the 'multiIndexed' variable Dictionary allows to quickly see the tree-like organization of the variables. Moreover, original and simplified variable names are now stored in the \"name\" and \"simplified_name\" columns, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablesDict = get_multiIndex_variablesDict(plain_variablesDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablesDict.loc[[\"CIBMTR - Cure Sickle Cell Disease\"],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the number of lines to be displayed for the future outputs\n",
    "pd.set_option(\"max.rows\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simple example to illustrate the ease of use a multiIndex dictionary. Let's say we are interested in every variable pertaining to \"5 - CRF data collection track only\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_study = variablesDict.index.get_level_values(0) == \"CIBMTR - Cure Sickle Cell Disease\"\n",
    "mask_transplant = variablesDict.index.get_level_values(1) == \"5 - CRF data collection track only\"\n",
    "transplant_variables = variablesDict.loc[mask_study & mask_transplant,:]\n",
    "transplant_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although pretty simple, it can be easily combined with other filters to quickly select necessary variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying and retrieving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second cornerstone of the API is the `query` object. It is how we retrieve data from the resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query = resource.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query object has several methods that enables us to build a query:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method | Arguments / Input | Output|\n",
    "|--------|-------------------|-------|\n",
    "| query.select.add() | variable names (string) or list of strings | all variables included in the list (no record subsetting)|\n",
    "| query.require.add() | variable names (string) or list of strings | all variables; only records that do not contain null values for input variables |\n",
    "| query.anyof.add() | variable names (string) or list of strings | all variables; only records that contain at least one non-null value for input variables |\n",
    "| query.filter.add() | variable name and additional filtering values | input variable; only records that match filter criteria |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 4 methods can be combined when building a query. The record eventually returned by the query has to meet all the different specified filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to select a cohort consisting of males with avascular necrosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting all variables from \"CIBMTR\" study\n",
    "mask_study = variablesDict.index.get_level_values(0) == \"CIBMTR - Cure Sickle Cell Disease\"\n",
    "varnames = variablesDict.loc[mask_study, \"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create variables that will look for males and avascular necrosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_var = variablesDict.loc[variablesDict[\"simplified_name\"] == \"Sex\", \"name\"].values[0]\n",
    "\n",
    "avascular_necrosis_varname = variablesDict.loc[variablesDict[\"simplified_name\"] == \"Avascular necrosis\", \"name\"].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablesDict.loc[variablesDict[\"simplified_name\"] == \"Avascular necrosis\", \"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filter by the variables by wanted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query = resource.query()\n",
    "my_query.select().add(avascular_necrosis_varname)\n",
    "my_query.filter().add(avascular_necrosis_varname, \"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query.select().add(sex_var)\n",
    "my_query.filter().add(sex_var, \"Male\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our query object is finally built, we use the `query.run` function to retrieve the data corresponding to our query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = my_query.getResultsDataFrame().set_index(\"Patient ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
